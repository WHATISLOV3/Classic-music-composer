# Classic music composer

В данном проекте c помощью рекуррентной нейронной сети решается задача генерации классической музыки, исполняемой на фортепиано.


## Процесс решения
Подготовка данных и обучение модели реализованы в файле
 *model_training.ipynb*.

### Подготовка данных

Исходными данными послужили 2 датасета *The MAESTRO
 Dataset v1.0 (2004 год)* и *Ibi dataset* (суммарно 116 mid/midi файлов).
  В первом датасете содержится классическая музыка, исполненная на фортепиано,
   с высоким темпом игры и большим количеством нот, а во втором современная
    музыка, тоже исполненная на фортепиано, но с низким или средним темпом 
     игры и небольшим 
количеством нот.

С помощью библиотеки *music21* из всех mid/midi файлов были извлечены 
ноты и аккорды, а затем добавлены в список нот всех файлов. Все ноты
упорядочены в порядке воспроизведения и не разделены специальными символами.

Далее были созданы словари для хранения всех уникальных нот. Всем звукам были сопоставлены натуральные числа, которые были подставлены в список нот всех файлов. Этот список является входными данными для модели. Выходные данные
 есть смещенные на 1 позицию влево входные данные. Также была написана функция, которая разделяла данные на батчи.


### Обучение модели
При решении задачи использовалась стандартная RNN lstm модель, написанная с
помощью библиотеки *PyTorch*. Lstm модель "запоминает" несколько последних символов и при предсказывании следующего основывается на них. При генерации
музыки это будет положительным аспектом, так как тогда выходная дорожка будет более похожа на мелодию.

Модель обучалась с использованием логистической функции ошибки и
оптимизатором Adam. Длительность обучения --- 300 эпох.

Достигнутая точность --- **0.7905** на эпохе 282 (45000 итерация).

### Генерация примеров

Генерация примеров реализована в файле *sample_generation.ipynb*.

При генерации примеров использовалась модель с состояниями 282 эпохи. Сначала
на вход модели подавались стартовые ноты, а затем, основываясь на предыдущие, она предсказывала новые звуки, которые добавлялись в список. Далее этот список
был переведён в поток и скомпилирован в midi файл.

В репозитории представлены 2 сгенерированных midi файла, также их mp3 версии. 


## Используемые библиотеки
* *music21* --- обработка midi файлов
* *numpy*, *PyTorch* --- создание модели
* *matplotlib* --- изображение графиков

Все необходимые для работы модули описаны в файле *requirements.txt*


## Исходные данные

* [The MAESTRO dataset](https://magenta.tensorflow.org/datasets/maestro#v100)

* [Ibi dataset](https://onedrive.live.com/?authkey=%21AO8HM8ZddtktiQ0&id=CE1D210F9FBC3B56%21752&cid=CE1D210F9FBC3B56)
